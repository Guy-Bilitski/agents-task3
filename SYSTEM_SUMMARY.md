# Multi-Stage Translation Chain System

## âœ… System Overview

This system implements a multi-stage translation pipeline using autonomous CLI-based agents to evaluate how spelling errors affect translation quality through a three-language chain: English â†’ French â†’ Hebrew â†’ English.

## ğŸ¯ Task Goal

Demonstrate a multi-stage translation pipeline that:
- Processes English sentences through three translation agents sequentially
- Evaluates how spelling errors in input affect final output quality
- Measures semantic drift using vector distance calculations
- Analyzes error impact across different spelling error percentages (0% to 50%)

## ğŸ“ Project Structure

```
agents-task3/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ en-fr-translator.md            ğŸ‡«ğŸ‡· Agent 1: English â†’ French
â”‚   â”‚   â”œâ”€â”€ fr-he-translator.md            ğŸ‡®ğŸ‡± Agent 2: French â†’ Hebrew
â”‚   â”‚   â”œâ”€â”€ he-en-translator.md            ğŸ‡¬ğŸ‡§ Agent 3: Hebrew â†’ English
â”‚   â”‚   â”œâ”€â”€ agent-validator.md             âœ“ Agent specification validator
â”‚   â”‚   â””â”€â”€ python-expert.md               ğŸ Python development support
â”‚   â”œâ”€â”€ copilot-instructions.md            ğŸ“‹ Agent directory
â”‚   â””â”€â”€ README.md                          ğŸ“„ GitHub Copilot info
â”œâ”€â”€ instructions.md                         ğŸ“– Complete documentation
â”œâ”€â”€ translation_experiments.csv             ğŸ“Š Experiment results
â”œâ”€â”€ utils.ipynb                            ğŸ”§ Python utilities & analysis
â”œâ”€â”€ requirements.txt                        ğŸ“¦ Python dependencies
â””â”€â”€ SYSTEM_SUMMARY.md                      ğŸ“„ This file
```

## ğŸ¯ How to Use the Translation Chain

### CLI Operation

The entire workflow runs through GitHub Copilot CLI using custom agents:

**Start the translation chain:**
```bash
@en-fr [Your English sentence here]
```

The chain executes automatically:
1. **@en-fr** translates English to French and triggers @fr-he
2. **@fr-he** translates French to Hebrew and triggers @he-en
3. **@he-en** translates Hebrew back to English (chain ends)

### Input Requirements

For task compliance:
- **Sentence length:** At least 15 words per sentence
- **Spelling errors:** Minimum 25% of words must contain spelling mistakes
- **Test range:** Run experiments with error levels from 0% to 50%

### Example Usage

```bash
@en-fr The qiuck brown fox jmups over the laazy dog in the garen during a beutiful sunny afternooon.
```

Output flow:
1. French translation appears
2. Hebrew translation appears  
3. Final English translation appears

## ğŸ”„ Translation Pipeline Architecture

### Agent Chain Flow

```
Input: English sentence (with spelling errors)
    â†“
Agent 1: @en-fr (English â†’ French)
    â†“
Agent 2: @fr-he (French â†’ Hebrew)
    â†“
Agent 3: @he-en (Hebrew â†’ English)
    â†“
Output: Final English sentence
```

### Self-Triggering Mechanism
- Each agent automatically calls the next agent in sequence
- **@en-fr** outputs French translation and triggers **@fr-he**
- **@fr-he** outputs Hebrew translation and triggers **@he-en**
- **@he-en** outputs final English translation and terminates the chain
- Users only need to call **@en-fr** to initiate the entire pipeline

### Intelligent Error Handling
- Agents translate based on **intended meaning**, not literal misspellings
- Example: "The qiuck brown fox" is understood as "The quick brown fox"
- Spelling errors are corrected through context-aware translation
- Semantic content is preserved throughout the chain

## ğŸ“Š Data Collection & Analysis

### CSV Data Structure

The `translation_experiments.csv` stores experimental data:

| Column | Description |
|--------|-------------|
| `original_sentence` | Input English text with spelling errors |
| `spelling_error_ratio` | Percentage of misspelled words (0.0 to 1.0) |
| `french_translation` | Output from Agent 1 (@en-fr) |
| `hebrew_translation` | Output from Agent 2 (@fr-he) |
| `final_english_translation` | Output from Agent 3 (@he-en) |
| `embedding_distance` | Vector distance between original and final English |

### Metrics Calculation

**Spelling Error Ratio:**
- Calculated before translation
- Formula: `(number of misspelled words) / (total words)`
- Measures input quality/corruption level

**Embedding Distance:**
- Calculated using Python sentence embeddings
- Compares original sentence vs. final output
- Measures semantic drift through translation chain
- Lower distance = better semantic preservation

### Experiment Protocol

1. Prepare English sentences (15+ words)
2. Introduce spelling errors (0% to 50% range)
3. Run through translation chain via CLI
4. Collect all translations (French, Hebrew, final English)
5. Calculate embedding distance using Python
6. Record all data in CSV
7. Generate graph: error percentage (x-axis) vs. distance (y-axis)

## ğŸ¤– Agent Specifications

### Agent 1: @en-fr (English â†’ French Translator)
- **Role:** Chain initiator
- **Input:** English text (handles spelling errors intelligently)
- **Output:** French translation + automatic trigger to @fr-he
- **Special capability:** Translates intended meaning, not literal misspellings
- **Configuration:** `.github/agents/en-fr-translator.md`

### Agent 2: @fr-he (French â†’ Hebrew Translator)
- **Role:** Chain middle
- **Input:** French text (from @en-fr)
- **Output:** Modern Hebrew translation + automatic trigger to @he-en
- **Format:** Unvocalized Hebrew text
- **Special capability:** Preserves tone and nuance from French
- **Configuration:** `.github/agents/fr-he-translator.md`

### Agent 3: @he-en (Hebrew â†’ English Translator)
- **Role:** Chain terminator
- **Input:** Hebrew text (from @fr-he)
- **Output:** Final English translation (no further triggers)
- **Special capability:** Natural, fluent English output
- **Configuration:** `.github/agents/he-en-translator.md`

### Supporting Agents

**@validator** - Agent specification reviewer
- Reviews and validates agent configuration files
- Identifies issues and recommends improvements
- Configuration: `.github/agents/agent-validator.md`

**@python-expert** - Python development assistant
- Supports Python code development
- Assists with embeddings, calculations, and plotting
- Configuration: `.github/agents/python-expert.md`

## ğŸ” Key Design Decisions

1. **Autonomous Agent Chain**
   - Each agent automatically triggers the next agent
   - @en-fr â†’ @fr-he â†’ @he-en (fully automated)
   - No manual intervention needed after initial call
   - Users only interact with @en-fr to start the chain

2. **Self-Triggering Architecture**
   - @en-fr outputs French translation and calls @fr-he
   - @fr-he outputs Hebrew translation and calls @he-en
   - @he-en outputs final English and terminates
   - Chain execution is completely transparent

3. **Intelligent Error Handling**
   - Spelling errors are handled by translating intended meaning
   - Context-aware translation preserves semantic content
   - Errors are corrected during translation, not rejected
   - Enables testing of error impact on semantic preservation

4. **CLI-Based Workflow**
   - Entire system operates through GitHub Copilot CLI
   - Custom agents triggered via @mentions
   - No external services or APIs required
   - Transparent, verifiable translation process

## ğŸ”¬ Experimental Design

### Error Level Testing

Run translation experiments across different spelling error percentages:

| Error Level | Description | Example Word Count (20 words) |
|-------------|-------------|-------------------------------|
| 0% | Perfect spelling | 0 errors |
| 10% | Minor errors | 2 errors |
| 25% | Moderate errors (minimum required) | 5 errors |
| 30% | Moderate-high errors | 6 errors |
| 40% | High errors | 8 errors |
| 50% | Maximum test level | 10 errors |

### Data Collection Workflow

1. **Prepare input sentences**
   - Each sentence must be at least 15 words
   - Create versions with 0%, 10%, 25%, 30%, 40%, 50% errors

2. **Run translation chain**
   - Call `@en-fr [sentence with errors]`
   - Capture French, Hebrew, and final English outputs
   - Record all translations in CSV

3. **Calculate metrics**
   - Compute spelling error ratio (input quality)
   - Generate embeddings for original and final English
   - Calculate vector distance (semantic drift)

4. **Generate visualization**
   - Plot error percentage (x-axis) vs. embedding distance (y-axis)
   - Analyze correlation between input errors and semantic drift
   - Document findings

## âœ… System Validation Checklist

- [x] Three translation agents configured (ENâ†’FRâ†’HEâ†’EN)
- [x] Self-triggering chain mechanism implemented
- [x] @en-fr agent triggers @fr-he automatically
- [x] @fr-he agent triggers @he-en automatically
- [x] @he-en agent terminates the chain
- [x] Intelligent spelling error handling implemented
- [x] CLI-based workflow through GitHub Copilot
- [x] CSV structure for data collection defined
- [x] Validator agent available for agent review
- [x] Python expert agent for development support
- [x] Instructions.md provides complete documentation
- [x] copilot-instructions.md lists all agents
- [x] Agent files use correct naming convention
- [x] UTF-8 encoding support for multilingual text

## ğŸ§ª Testing Examples

Test the translation chain with these examples:

**Test 1: Perfect spelling (0% errors)**
```bash
@en-fr The quick brown fox jumps over the lazy dog in the beautiful garden during the sunny afternoon.
```

**Test 2: Minimum required errors (25% errors, 15+ words)**
```bash
@en-fr The qiuck brown fox jmups over the laazy dog in the garen during a beutiful sunny afternooon.
```

**Test 3: High error level (40% errors)**
```bash
@en-fr Ther's a reeson legandary formr Liverpool managr Bill Shankly once proclamed footbal was the peopel's game becaus it belngs to the fans.
```

**Test 4: Maximum test level (50% errors)**
```bash
@en-fr Machine lerning modls requir larg dataseets for traning purpses and accurte predctions in reel world aplications.
```

## ğŸ“‹ Deliverables Checklist

### Required Outputs

**Agent Configurations** âœ…
- `.github/agents/en-fr-translator.md` (Agent 1: ENâ†’FR)
- `.github/agents/fr-he-translator.md` (Agent 2: FRâ†’HE)
- `.github/agents/he-en-translator.md` (Agent 3: HEâ†’EN)

**Input Sentences** (To be completed)
- Original sentences (15+ words each)
- Versions with spelling errors (0% to 50%)
- Sentence lengths documented

**Translation Results** (To be completed)
- French translations from Agent 1
- Hebrew translations from Agent 2
- Final English translations from Agent 3
- All data recorded in `translation_experiments.csv`

**Metrics & Analysis** (To be completed)
- Spelling error ratios calculated
- Embedding distances computed  
- Python code for embeddings (in `utils.ipynb`)

**Visualization** (To be completed)
- Graph: Error percentage (x-axis) vs. Vector distance (y-axis)
- Shows correlation between errors and semantic drift
- Generated using Python (matplotlib/seaborn)

**Documentation** âœ…
- Complete system documentation (`instructions.md`)
- System summary (`SYSTEM_SUMMARY.md`)
- Agent specifications (all `.md` files)

## ğŸ“ Usage Notes

- **CLI Entry Point:** Call `@en-fr [your sentence]` to start the chain
- **Automatic Execution:** Chain runs ENâ†’FRâ†’HEâ†’EN without manual intervention
- **Transparent Process:** All intermediate translations are displayed
- **Error Handling:** Spelling errors are intelligently corrected via context-aware translation
- **Manual Usage:** Individual agents (@fr-he, @he-en) can be called separately (breaks auto-chain)
- **Data Collection:** Record all inputs/outputs in `translation_experiments.csv`
- **Analysis:** Use `utils.ipynb` for embeddings, distance calculations, and visualization

## ğŸ“ Project Summary

This multi-stage translation chain system demonstrates:

1. âœ… **CLI-Based Agent Workflow** - Entire pipeline runs through GitHub Copilot CLI
2. âœ… **Three-Agent Translation Chain** - ENâ†’FRâ†’HEâ†’EN with automatic triggering
3. âœ… **Intelligent Error Handling** - Context-aware translation of misspelled input
4. âœ… **Semantic Drift Analysis** - Vector distance measurement between original and final output
5. âœ… **Experimental Protocol** - Test error levels from 0% to 50%
6. âœ… **Data-Driven Insights** - Graph showing error impact on translation quality

**Entry Point:** `@en-fr [your English sentence]`  
**Chain Flow:** ENâ†’FRâ†’HEâ†’EN (fully automated)  
**Analysis:** Embedding distance vs. spelling error percentage

---

**System Status:** âœ… READY TO USE  
**Entry Point:** `@en-fr [your English sentence]`  
**Last Updated:** 2025-11-26  
**Version:** 2.0
